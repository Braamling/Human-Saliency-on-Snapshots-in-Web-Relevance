{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from preprocessing.contextualFeaturesGenerator.utils.LETORIterator import LETORIterator\n",
    "from scipy.stats import ttest_rel\n",
    "from utils.evaluate import Evaluate \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_LTR_metrics(file, ids, metrics):\n",
    "    results = []\n",
    "    for idx in ids:\n",
    "        df = pd.read_pickle(file.format(idx))\n",
    "        for column in df:\n",
    "            if type(column) is int:\n",
    "                # Get a ranking with the respective scores.\n",
    "                ranking = df[str(column) + \"_s\"].as_matrix()\n",
    "                \n",
    "                # Remove all nans\n",
    "                ranking = [int(x) for x in ranking if not math.isnan(float(x))]\n",
    "                \n",
    "                # Calculate the evaluation scores\n",
    "                scores = Evaluate.compute_scores(ranking)\n",
    "                \n",
    "                # Append all evaluation scores together with its query id in the correct order\n",
    "                results.append([column] + [scores[i] for i in metrics])\n",
    "                \n",
    "    df = pd.DataFrame(results, columns=[\"query_id\"] + metrics)\n",
    "    return df.groupby(\"query_id\", as_index=False).mean().sort_values(by=[\"query_id\"])\n",
    "\n",
    "def get_baseline_df(test_file, score_file, metrics):\n",
    "    queries = []\n",
    "    scores = []\n",
    "    prev_query_id = -1\n",
    "    for i in range(1, 6):\n",
    "        iterator = LETORIterator(test_file.format(i))\n",
    "        with open(score_file.format(i), \"r\") as f:\n",
    "            for line, (d_query_id, doc_id, rel_score, _) in zip(f, iterator.feature_iterator()):\n",
    "                s_query_id, _, score = line.rstrip().split(\"\\t\")\n",
    "                s_query_id, score = int(s_query_id), float(score)\n",
    "\n",
    "                assert int(s_query_id) == int(d_query_id), str(s_query_id) + \" != \" + str(d_query_id)\n",
    "                \n",
    "                if prev_query_id == -1:\n",
    "                    prev_query_id = s_query_id\n",
    "                    \n",
    "                \n",
    "                if s_query_id != prev_query_id:\n",
    "                    prev_query_id = s_query_id\n",
    "                    if len(scores) > 0:\n",
    "                        scores = sorted(scores, key=lambda x: -x[1])\n",
    "                        queries.append((s_query_id, scores))\n",
    "                        scores = []\n",
    "                \n",
    "\n",
    "\n",
    "                scores.append((int(rel_score), score))\n",
    "    if len(scores) > 0:\n",
    "        scores = sorted(scores, key=lambda x: -x[1])\n",
    "        queries.append((s_query_id, scores))\n",
    "        scores = []\n",
    "    \n",
    "    results = []\n",
    "    for query, rank in queries:\n",
    "        ranking = list(zip(*rank))[0]\n",
    "\n",
    "        # Calculate the evaluation scores\n",
    "        scores = Evaluate.compute_scores(ranking)\n",
    "                \n",
    "        # Append all evaluation scores together with its query id in the correct order\n",
    "        results.append([query] + [scores[i] for i in metrics])\n",
    "   \n",
    "    df = pd.DataFrame(results, columns=[\"query_id\"] + metrics)\n",
    "    return df.sort_values(by=[\"query_id\"])\n",
    "\n",
    "def t_test(df_1, df_2, metrics):\n",
    "    results = []\n",
    "    for metric in metrics:\n",
    "        results.append((metric, ttest_rel(df_1[metric], df_2[metric]).pvalue))\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_path = \"storage/logs\"\n",
    "files = [\"_baseline_masks_{}.pkl\",\n",
    "        \"_ViP_snapshots_{}.pkl\",\n",
    "        \"_ViP_highlights_{}.pkl\",\n",
    "        \"_vgg16_snapshots_{}.pkl\",\n",
    "        \"_vgg16_highlights_{}.pkl\",\n",
    "        \"_vgg16_saliency_{}.pkl\"]\n",
    "metrics = [\"p@1\",\"p@5\",\"p@10\",\"ndcg@1\",\"ndcg@5\",\"ndcg@10\",\"map\"]\n",
    "\n",
    "ids = range(1, 26)\n",
    "vis_dfs = []\n",
    "for file in files: \n",
    "    vis_dfs.append(get_all_LTR_metrics(os.path.join(pickle_path, file), ids, metrics).set_index(\"query_id\"))\n",
    "    \n",
    "rankboost_df = get_baseline_df(\"storage/clueweb12_3.0/Fold{}/vali.txt\", \"storage/baseline/scores/rankboost_{}\", metrics).set_index(\"query_id\")\n",
    "lambdamart_df = get_baseline_df(\"storage/clueweb12_3.0/Fold{}/vali.txt\", \"storage/baseline/scores/lambdamart_{}\", metrics).set_index(\"query_id\")\n",
    "adarank_df = get_baseline_df(\"storage/clueweb12_3.0/Fold{}/vali.txt\", \"storage/baseline/scores/adarank_{}\", metrics).set_index(\"query_id\")\n",
    "\n",
    "rankboost_img_df = get_baseline_df(\"storage/clueweb12_3.0_images/Fold{}/vali.txt\", \"storage/baseline/scores/rankboost_img_{}\", metrics).set_index(\"query_id\")\n",
    "lambdamart_img_df = get_baseline_df(\"storage/clueweb12_3.0_images/Fold{}/vali.txt\", \"storage/baseline/scores/lambdamart_img_{}\", metrics).set_index(\"query_id\")\n",
    "adarank_img_df = get_baseline_df(\"storage/clueweb12_3.0_images/Fold{}/vali.txt\", \"storage/baseline/scores/adarank_img_{}\", metrics).set_index(\"query_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('p@1', 0.1686891822549483),\n",
       " ('p@5', 0.02258328305624949),\n",
       " ('p@10', 0.023535194855763938),\n",
       " ('ndcg@1', 0.10725594035410112),\n",
       " ('ndcg@5', 0.04033611190120678),\n",
       " ('ndcg@10', 0.019671659970410094),\n",
       " ('map', 0.2611927839414759)]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t_test( vis_dfs[4], lambdamart_img_df, metrics)\n",
    "# t_test( adarank_df, lambdamart_df, metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambdamart_img_df = lambdamart_img_df.set_index(\"query_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p@1         8\n",
       "p@5        19\n",
       "p@10       16\n",
       "ndcg@1     16\n",
       "ndcg@5     24\n",
       "ndcg@10    27\n",
       "map         4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambdamart_img_df.reset_index(drop=True) <vis_dfs[4].reset_index(drop=True)).sum() - (lambdamart_img_df.reset_index(drop=True) >vis_dfs[4].reset_index(drop=True)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p@1        0.554000\n",
       "p@5        0.478400\n",
       "p@10       0.453200\n",
       "ndcg@1     0.309833\n",
       "ndcg@5     0.295540\n",
       "ndcg@10    0.301756\n",
       "map        0.421551\n",
       "dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_dfs[5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-1.633197682259768, pvalue=0.1056039630262534)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(rankboost_img_df[\"p@1\"]*10, vis_dfs[4][\"p@1\"]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query_id\n",
       "201    0.84\n",
       "202    0.00\n",
       "203    0.72\n",
       "204    0.76\n",
       "205    0.72\n",
       "206    0.96\n",
       "207    1.00\n",
       "208    0.20\n",
       "209    0.32\n",
       "210    0.36\n",
       "211    0.40\n",
       "212    0.64\n",
       "213    0.60\n",
       "214    1.00\n",
       "215    0.40\n",
       "216    0.96\n",
       "217    0.88\n",
       "218    0.28\n",
       "219    0.44\n",
       "220    0.28\n",
       "221    0.96\n",
       "222    0.76\n",
       "223    0.96\n",
       "224    0.28\n",
       "225    0.00\n",
       "226    0.44\n",
       "227    0.28\n",
       "228    0.68\n",
       "229    0.68\n",
       "230    0.28\n",
       "       ... \n",
       "271    0.00\n",
       "272    0.80\n",
       "273    0.08\n",
       "274    0.28\n",
       "275    0.00\n",
       "276    0.76\n",
       "277    0.44\n",
       "278    0.00\n",
       "279    0.60\n",
       "280    0.96\n",
       "281    0.92\n",
       "282    0.96\n",
       "283    0.40\n",
       "284    1.00\n",
       "285    0.96\n",
       "286    0.44\n",
       "287    0.04\n",
       "288    0.80\n",
       "289    0.00\n",
       "290    0.28\n",
       "291    0.32\n",
       "292    0.88\n",
       "293    0.68\n",
       "294    0.92\n",
       "295    0.48\n",
       "296    0.92\n",
       "297    0.96\n",
       "298    0.48\n",
       "299    0.84\n",
       "300    0.52\n",
       "Name: p@5, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
