% !TEX root = cikm2018-visual-ltr.tex

\section{Introduction}
The design and appearance of a web are a determining factor for a user to examine a page or divert to another page~\cite{nielsen1999designing,nielsen2006f,pernice2017f,wang2014eye}.
Relatively little is known about the potential of visual features to help determine the perceived relevance of  a (web) page, in addition to content features such as BM25, quality indicators such as PageRank and behavioral features such as CTR.
Recently, \citet{fan2017learning} have introduced ViP, a \ac{LTR} model that uses a combination of both visual and content features.
Visual features are calculated from snapshots, which are in turn created by rendering web pages.
The authors demonstrate that adding these visual features helps to significantly improve the \ac{LTR} performance.

The work by \citet{fan2017learning} is important because it indicates that the visual appearance of a web page can have a significant impact on perceived utility, which opens a new direction in web search and \ac{LTR}.
However, there are several limitations in \cite{fan2017learning}.
First, the method used to extract visual features in the ViP architecture, which 
\begin{inparaenum}[(i)]
\item is based on a strong assumption that users view websites in an F-shape pattern, 
\item grayscales and shrinks the input images to $64\times64$, and
\item does not use a state-of-the-art visual feature extraction method.
\end{inparaenum}

A second limitation in~\citep{fan2017learning} is that
the rendered web pages in the collection shared in~\citep{fan2017learning} come from the the GOV2 collection~\todo{ref}.\footnote{\url{http://ir.dcs.gla.ac.uk/test_collections/gov2-summary.htm}}
This collection is limited in the sense that:
\begin{inparaenum}[(i)]
\item it solely contains web pages within the .gov domain crawled in 2004, i.e., somewhat outdated pages with a relatively narrow scope, and
\item the web pages in the dataset do not contain their original images.
%\item the styling information is not available together with web pages \todo{what do we mean with this?}.
\end{inparaenum}
In order to advance research on \ac{LTR} with visual features it is important to have a dataset with more diverse and up-to-date documents and richer visual information (e.g., styling, images, etc).

In this work, we address the above limitations.
First, we propose the following two methods to extract visual features from snapshots:
\begin{inparaenum}[(i)]
\item transfer learning from a pre-trained image recognition model~\cite{donahue2014decaf,simonyan2014very}, and
\item generation of synthetic saliency heatmaps from the web page snapshots~\cite{shen2014webpage,shan2017two}.
\end{inparaenum}
We show that both methods are able to improve retrieval performance significantly.

Second, we propose \datasetname, a dataset that contains rich and highly diverse snapshots from the ClueWeb12 collection.\footnote{\url{https://lemurproject.org/clueweb12/}} The snapshots are acquired for judged documents in the TREC Web Track 2013 \& 2014 topics~\cite{collins2013trec,collins2015trec}. For each document, we also calculate content features, such as BM25 and TF-IDF, that can be used for \ac{LTR}.
The proposed dataset is made publicly available.\footnote{URL removed for review.}

%\todo{describe key features of the proposed dataset by unfolding the next sentence into a few sentences}
%
%We believe that this dataset allows the \ac{LTR} research community to investigate various methods of using visual features for search and ranking.
Third, using \datasetname, we show that the results of the ViP model~\citep{fan2017learning} can be reproduced on a more diverse dataset.

In summary, the main contributions of this work are:
\begin{inparaenum}[(i)]
\item We improve ViP by applying a transfer learning feature extractor and using synthetic saliency heatmaps as visual input. \mdr{Do we need to introduce names for the new method(s) here?}
\item We propose and publish \datasetname, an out-of-the-box dataset for \ac{LTR} with visual features.
\item We reproduce the ViP model from \cite{fan2017learning} on the newly proposed dataset.
\end{inparaenum}
\if0
\todo{Revise this if we have space or drop it.} The rest of the paper is organized as follows. Section~\ref{sec:dataset} describes the collection process that was used to construct \datasetname. In Section~\ref{sec:experiments} we reproduce the work of \citet{fan2017learning} and demonstrate various feature extraction methods on \datasetname~and set a baseline for future visual \ac{LTR} research.  
\fi